{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_composed = transforms.Compose([\n",
    "                        transforms.Resize((512,1024)),\n",
    "#                         transforms.RandomRotation(degrees=30),\n",
    "#                         transforms.RandomHorizontalFlip(p=1),\n",
    "])\n",
    "\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv',transforms = transforms_composed)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=1,\n",
    "                          num_workers=1,\n",
    "                          shuffle=False)\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=2,\n",
    "                          num_workers=1,\n",
    "                          shuffle=True)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "model = torch.load('best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates the pixel accuracy and iou accuracy per class for the validation dataset\n",
    "\"\"\"\n",
    "\n",
    "def val(epoch,flag = True):\n",
    "    p_acc = 0\n",
    "    iou_acc = 0\n",
    "    iou_int = []\n",
    "    iou_union = []\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        if use_gpu:\n",
    "            X = X.cuda()\n",
    "            tar = tar.cuda()\n",
    "            Y = Y.cuda()\n",
    "        else:\n",
    "            X,tar,Y = X.cpu(), tar.cpu(),Y.cpu()\n",
    "            \n",
    "        if flag:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X)\n",
    "            losses.append(criterion(outputs, Y).item())\n",
    "            continue\n",
    "        p, iou_i, iou_u = model.evaluate(X, tar,Y)\n",
    "        p_acc += p\n",
    "        iou_int.append(iou_i)\n",
    "        iou_union.append(iou_u) \n",
    "        count += 1\n",
    "    if flag:\n",
    "        return np.mean(np.array(losses))\n",
    "    iou_int = np.sum(np.array(iou_int),axis=0)\n",
    "    iou_union = np.sum(np.array(iou_union),axis=0)\n",
    "    iou_acc = iou_int/iou_union\n",
    "    print(iou_acc)\n",
    "    print(iou_acc.shape)\n",
    "    print(\"Epoch {}: Pixel Acc: {}, IOU Acc: {}\".format(epoch, p_acc/count, np.mean(iou_acc)))\n",
    "    print(\"building{}, traffic sign{}, person{}, car{}, bicycle{}\".format(\n",
    "        iou_acc[2],iou_acc[7],iou_acc[11],iou_acc[13],iou_acc[18]))\n",
    "    return p_acc/count, np.mean(iou_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of segmented output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualizations of the segmented output for the first image in the provided test.csv overlaid on the image.\n",
    "\"\"\"\n",
    "for iter, (X, tar, Y) in enumerate(test_loader):\n",
    "    print(X.shape)\n",
    "    Y = Y.cpu().data.numpy()\n",
    "    print(\"Ground truth\")\n",
    "    plt.imshow(Y[0], cmap='hot', interpolation='nearest')\n",
    "    plt.figure()\n",
    "    img = np.zeros((Y.shape[1],Y.shape[2],3))\n",
    "    for ind in range(n_class):\n",
    "        arg = np.argwhere(Y[0]==ind)\n",
    "        img[arg[:,0],arg[:,1],0] = labels_classes[ind].color[0]\n",
    "        img[arg[:,0],arg[:,1],1] = labels_classes[ind].color[1]\n",
    "        img[arg[:,0],arg[:,1],2] = labels_classes[ind].color[2]\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.figure()\n",
    "    print(\"Predicted\")\n",
    "    pred = model(X.cuda())\n",
    "    Y = pred.argmax(dim = 1)\n",
    "    Y = Y.cpu().data.numpy()\n",
    "    plt.imshow(Y[0], cmap='hot', interpolation='nearest')\n",
    "    plt.figure()\n",
    "    print(Y.shape)\n",
    "    img = np.zeros((Y.shape[1],Y.shape[2],3))\n",
    "    for ind in range(n_class):\n",
    "        arg = np.argwhere(Y[0]==ind)\n",
    "        img[arg[:,0],arg[:,1],0] = labels_classes[ind].color[0]\n",
    "        img[arg[:,0],arg[:,1],1] = labels_classes[ind].color[1]\n",
    "        img[arg[:,0],arg[:,1],2] = labels_classes[ind].color[2]\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.imsave('baseline.png',img.astype(np.uint8))\n",
    "    plt.figure()\n",
    "    to_pil = torchvision.transforms.ToPILImage()\n",
    "    img = to_pil(X[0])\n",
    "    plt.imshow(img)\n",
    "    print(val(100,False))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
